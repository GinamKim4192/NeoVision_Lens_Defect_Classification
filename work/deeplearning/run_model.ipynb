{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from model_create import create_poweradeNet, create_parisbaguetteNet, create_MangoNet, create_americano, vgg19, resnet\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from modify_ImageDataGenerator import custom_ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical, plot_model, Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "from itertools import chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, Dense, AveragePooling2D, BatchNormalization, Flatten, Dropout, ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet import ResNet50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11771/11771 [03:12<00:00, 61.08it/s]\n",
      "100%|██████████| 2942/2942 [00:51<00:00, 57.25it/s]\n",
      "100%|██████████| 3904/3904 [01:14<00:00, 52.28it/s]\n",
      "100%|██████████| 860/860 [00:17<00:00, 50.13it/s]\n",
      "100%|██████████| 3000/3000 [01:00<00:00, 49.82it/s]\n",
      "100%|██████████| 600/600 [00:12<00:00, 48.32it/s]\n",
      "100%|██████████| 3134/3134 [01:00<00:00, 51.76it/s]\n",
      "100%|██████████| 610/610 [00:10<00:00, 56.05it/s]\n",
      "100%|██████████| 4760/4760 [01:22<00:00, 57.52it/s]\n",
      "100%|██████████| 1000/1000 [00:17<00:00, 55.67it/s]\n",
      "100%|██████████| 5759/5759 [01:40<00:00, 57.52it/s]\n",
      "100%|██████████| 1435/1435 [00:23<00:00, 61.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# def image_preprocessing(image):\n",
    "#     image = np.array(image)\n",
    "#     image_resize = cv2.resize(image, dsize = (400, 400))\n",
    "#     image_hsv = cv2.cvtColor(image_resize, cv2.COLOR_RGB2HSV)\n",
    "#     image_scaled = image_hsv.copy()\n",
    "#     image_scaled[:,:,0] = image_hsv[:,:,0] / 180.\n",
    "#     image_scaled[:,:,1] = image_hsv[:,:,1] / 255.\n",
    "#     image_scaled[:,:,2] = image_hsv[:,:,2] / 255.\n",
    "#     return image_scaled\n",
    "#\n",
    "# train_gen = custom_ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "# test_gen = custom_ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "# val_gen = custom_ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "#\n",
    "#\n",
    "# train_flow_gen = train_gen.flow_from_directory(\n",
    "#     directory=f'./model_images/DA4649_rotate/train', color_mode = 'rgb',\n",
    "#     target_size=(400, 400), class_mode='categorical', batch_size=32, shuffle=False)\n",
    "# test_flow_gen = test_gen.flow_from_directory(\n",
    "#     directory=f'./model_images/DA4649_rotate/test', color_mode = 'rgb',\n",
    "#     target_size=(400, 400), class_mode='categorical', batch_size=32, shuffle=False)\n",
    "# val_flow_gen = val_gen.flow_from_directory(\n",
    "#     directory=f'./model_images/{item_code}/validation', color_mode = color_mode,\n",
    "#     target_size=img_shape[:2], class_mode='categorical', batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# def image_preprocessing(image):\n",
    "#     image = np.array(image)\n",
    "#     image_resize = cv2.resize(image, dsize = (400, 400))\n",
    "#     image_scaled = image_resize.copy()\n",
    "#     image_scaled[:,:,0] = image_resize[:,:,0] / 255.\n",
    "#     image_scaled[:,:,1] = image_resize[:,:,1] / 255.\n",
    "#     image_scaled[:,:,2] = image_resize[:,:,2] / 255.\n",
    "#     return image_scaled\n",
    "#\n",
    "# train_gen = ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "# test_gen = ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "# val_gen = ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "#\n",
    "#\n",
    "# train_flow_gen = train_gen.flow_from_directory(\n",
    "#     directory=f'./model_images/DA4649_rotate/train', color_mode = 'rgb',\n",
    "#     target_size=(400, 400), class_mode='categorical', batch_size=32, shuffle=False)\n",
    "# test_flow_gen = test_gen.flow_from_directory(\n",
    "#     directory=f'./model_images/DA4649_rotate/test', color_mode = 'rgb',\n",
    "#     target_size=(400, 400), class_mode='categorical', batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "def load_img(dir, img_name):\n",
    "    img = cv2.imread(f'{dir}/{img_name}')\n",
    "    img_resize = cv2.resize(img, dsize=(400, 400))\n",
    "    img_hsv = cv2.cvtColor(img_resize, cv2.COLOR_BGR2HSV)\n",
    "    img_hsv = np.asarray(img_hsv, dtype = np.float32)\n",
    "    img_scaled = img_hsv.copy()\n",
    "    img_scaled[:, :, 0] = img_hsv[:, :, 0] / 180.\n",
    "    img_scaled[:, :, 1] = img_hsv[:, :, 1] / 255.\n",
    "    img_scaled[:, :, 2] = img_hsv[:, :, 2] / 255.\n",
    "    return img_scaled\n",
    "\n",
    "def create_gen(lens_class, y_value):\n",
    "    # train 이미지 배열 및 target값 만들기\n",
    "    img_train_gen = [load_img(f'./model_images/DA4649_rotate/train/{lens_class}', i)\n",
    "                     for i in tqdm(os.listdir(f'./model_images/DA4649_rotate/train/{lens_class}'))]\n",
    "    train_y_arr = np.full(len(os.listdir(f'./model_images/DA4649_rotate/train/{lens_class}')), y_value)\n",
    "\n",
    "    # test 이미지 배열 및 target값 만들기\n",
    "    img_test_gen = [load_img(f'./model_images/DA4649_rotate/test/{lens_class}', i)\n",
    "                    for i in tqdm(os.listdir(f'./model_images/DA4649_rotate/test/{lens_class}'))]\n",
    "    test_y_arr = np.full(len(os.listdir(f'./model_images/DA4649_rotate/test/{lens_class}')), y_value)\n",
    "    return img_train_gen, train_y_arr, img_test_gen, test_y_arr\n",
    "\n",
    "train_normal, train_normal_y, test_normal, test_normal_y = create_gen('1_normal', 0)\n",
    "train_center, train_center_y, test_center, test_center_y = create_gen('2_center_rotate_per30', 1)\n",
    "train_colorpoor, train_colorpoor_y, test_colorpoor, test_colorpoor_y = create_gen('3_colorpoor_rotate_per5', 2)\n",
    "train_dotmissing, train_dotmissing_y, test_dotmissing, test_dotmissing_y = create_gen('4_dotmissing_rotate_per5', 3)\n",
    "train_inkcut, train_inkcut_y, test_inkcut, test_inkcut_y = create_gen('5_inkcut_rotate_per15', 4)\n",
    "train_line, train_line_y, test_line, test_line_y = create_gen('6_line_rotate_per60', 5)\n",
    "\n",
    "train_X = np.asarray(train_normal + train_center + train_colorpoor + train_dotmissing + train_inkcut + train_line)\n",
    "test_X = np.asarray(test_normal + test_center + test_colorpoor + test_dotmissing + test_inkcut + test_line)\n",
    "\n",
    "train_Y = to_categorical(np.concatenate((train_normal_y, train_center_y, train_colorpoor_y, train_dotmissing_y, train_inkcut_y, train_line_y), axis=0),6)\n",
    "test_Y = to_categorical(np.concatenate((test_normal_y, test_center_y, test_colorpoor_y, test_dotmissing_y, test_inkcut_y, test_line_y), axis=0),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20800\\53619997.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m custom_gen_normal = Custom_generator(src_path='./model_images/DA4649_rotate/train/1_normal',\n\u001B[1;32m---> 60\u001B[1;33m                                      input_shape=(400, 400, 3), target = np.array[0, 0, 0, 0, 0, 1], batch_size=32, is_train=True)\n\u001B[0m\u001B[0;32m     61\u001B[0m custom_gen_center = Custom_generator('./model_images/DA4649_rotate/train/2_center_rotate_per30',\n\u001B[0;32m     62\u001B[0m                                     (400, 400, 3), target = np.array[0, 0, 0, 0, 1, 0], batch_size=32, is_train=True)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "class Custom_generator(Sequence):\n",
    "    def __init__(self, src_path, input_shape, target, batch_size, is_train=False):\n",
    "        folder_list = os.listdir(src_path)\n",
    "        self.src_len = len(os.listdir(src_path))\n",
    "        self.is_train = is_train\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.target = target\n",
    "        self.x, self.y = [], []\n",
    "\n",
    "        with open(\"./datasets/wnids.txt\", \"r\") as f:\n",
    "            cls_list = f.readlines()\n",
    "        cls_list = [cls_object.replace(\"\\n\", \"\") for cls_object in cls_list]\n",
    "\n",
    "        for _, folder in enumerate(folder_list):\n",
    "            imgs = glob.glob(src_path+folder+\"/*.JPEG\")\n",
    "            cls = cls_list.index(folder)\n",
    "            self.x += imgs\n",
    "            self.y += list(np.full((len(imgs)), fill_value=cls))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.x))\n",
    "        if self.is_train:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return round(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x, batch_y = [], []\n",
    "        batch_index = self.index[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        for i in batch_index:\n",
    "            batch_x.append(self.x[i])\n",
    "            batch_y.append(self.y[i])\n",
    "        out_x, out_y = self.data_gen(batch_x, batch_y)\n",
    "        return out_x, out_y\n",
    "\n",
    "    def data_gen(self, x, y):\n",
    "        input_x = np.zeros((self.batch_size, self.input_shape[0], self.input_shape[1], self.input_shape[2]), dtype=np.float32)\n",
    "        copy_input_x = []\n",
    "        imgs = []\n",
    "        for idx in range(len(x)):\n",
    "            img = cv2.imread(x[idx])\n",
    "            input_x[idx] = cv2.resize(img, (self.input_shape[0], self.input_shape[1]))\n",
    "            input_x[idx] = cv2.cvtColor(input_x[idx], cv2.COLOR_BGR2HSV)\n",
    "            input_x[idx] = np.asarray(input_x, np.float32)\n",
    "            copy_input_x[idx] = input_x[idx].copy()\n",
    "            input_x[idx][:,:,0] = copy_input_x[:,:,0] / 180.\n",
    "            input_x[idx][:,:,1] = copy_input_x[:,:,1] / 255.\n",
    "            input_x[idx][:,:,2] = copy_input_x[:,:,2] / 255.\n",
    "\n",
    "        input_y = np.full(self.src_len, self.target)\n",
    "        return input_x, input_y\n",
    "\n",
    "    # def __init__(self, src_path, input_shape, target, batch_size, is_train=False):\n",
    "\n",
    "custom_gen_normal = Custom_generator(src_path='./model_images/DA4649_rotate/train/1_normal',\n",
    "                                     input_shape=(400, 400, 3), target = np.array[0, 0, 0, 0, 0, 1], batch_size=32, is_train=True)\n",
    "custom_gen_center = Custom_generator('./model_images/DA4649_rotate/train/2_center_rotate_per30',\n",
    "                                    (400, 400, 3), target = np.array[0, 0, 0, 0, 1, 0], batch_size=32, is_train=True)\n",
    "custom_gen_colorpoor = Custom_generator('./model_images/DA4649_rotate/train/3_colorpoor_rotate_per5',\n",
    "                                        (400, 400, 3), target = np.array[0, 0, 0, 1, 0, 0], batch_size=32, is_train=True)\n",
    "custom_gen_dotmissing = Custom_generator('./model_images/DA4649_rotate/train/4_dotmissing_rotate_per5',\n",
    "                                        (400, 400, 3), target = np.array[0, 0, 1, 0, 0, 0], batch_size=32, is_train=True)\n",
    "custom_gen_inkcut = Custom_generator('./model_images/DA4649_rotate/train/5_inkcut_rotate_per15',\n",
    "                                    (400, 400, 3), target = np.array[0, 1, 0, 0, 0, 0], batch_size=32, is_train=True)\n",
    "custom_gen_line = Custom_generator('./model_images/DA4649_rotate/train/6_line_rotate_per60',\n",
    "                                    (400, 400, 3), target = np.array[1, 0, 0, 0, 0, 0], batch_size=32, is_train=True)\n",
    "\n",
    "train_gen = chain(custom_gen_normal, custom_gen_center, custom_gen_colorpoor, custom_gen_dotmissing, custom_gen_inkcut, custom_gen_line)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('modify')\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "model = create_americano(shape=(400, 400, 3), classes=6)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "item_code = 'DA4649_rotate'\n",
    "epochs = 10\n",
    "now = time.localtime()\n",
    "checkpoint_filename = f'{now[0]}{now[1]:0>2}{now[2]:0>2}{now[3]:0>2}{now[4]:0>2}_defect.h5'\n",
    "# 체크포인트\n",
    "cb_checkpoint = ModelCheckpoint(filepath=f'model_hdf5/{checkpoint_filename}', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                save_weight_only=True)\n",
    "history = model.fit(train_gen,\n",
    "                    epochs=epochs,\n",
    "                    callbacks =[cb_checkpoint],\n",
    "                    # validation_data=(test_X, test_Y),\n",
    "                    batch_size=32,\n",
    "                    )\n",
    "\n",
    "# model.evaluate(x=test_X, y=test_Y, batch_size = 32)\n",
    "\n",
    "\n",
    "# # confusion matrix 출력\n",
    "# \n",
    "# real_target =\n",
    "# predict_target = []\n",
    "# for i in model.predict(x=test_X):\n",
    "#     predict_target.append(np.argmax(i))\n",
    "#\n",
    "# predict_target = np.asarray(predict_target)\n",
    "# con = tf.math.confusion_matrix(labels=real_target, predictions=predict_target)\n",
    "# print('\\n\\n\\n\\n>> confusion_matrix')\n",
    "# print(con)\n",
    "\n",
    "# 학습 그래프 출력\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accucarcy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model(model = model, to_file='mangoNet.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
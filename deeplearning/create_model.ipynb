{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1a2070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T07:49:16.737628Z",
     "start_time": "2022-01-18T07:49:13.290816Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Flatten, Concatenate, Activation, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.resnet import ResNet101\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878a3142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T07:49:16.752588Z",
     "start_time": "2022-01-18T07:49:16.738624Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 이미지 전처리 함수\n",
    "\n",
    "# HSV로 변환\n",
    "# 학습 모델에서는 이미지를 rgb를 읽어옴. 서버 프로그램에서는 bgr로 이미지를 읽어와서 서버에서는 bgr을 rgb로 convert 해줘야함.\n",
    "def image_preprocessing(image):\n",
    "    image = np.array(image)\n",
    "    image_resize = cv2.resize(image, dsize = (400, 400))\n",
    "    image_hsv = cv2.cvtColor(image_resize, cv2.COLOR_RGB2HSV)\n",
    "    image_scaled = image_hsv.copy()\n",
    "    image_scaled[:,:,0] = image_hsv[:,:,0] / 180.\n",
    "    image_scaled[:,:,1] = image_hsv[:,:,1] / 255.\n",
    "    image_scaled[:,:,2] = image_hsv[:,:,2] / 255.\n",
    "    return image_scaled\n",
    "\n",
    "# # GrayScale로 변환\n",
    "# def image_preprocessing(image):\n",
    "#     image_gray_reshape = image.reshape(image.shape[0],image.shape[1], 1)\n",
    "#     image_scaled = image_gray_reshape / 255.\n",
    "#     return image_scaled\n",
    "\n",
    "# GoogleNet Inception\n",
    "def inception(x_in, x1_f,x3r_f,x3_f,x5r_f,x5_f,po):\n",
    "\n",
    "    x1 = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding = 'SAME')(x_in)\n",
    "    x1 = Conv2D(filters= po,kernel_size=(1,1),padding=\"SAME\")(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv2D(filters=x5r_f,kernel_size=(1,1),padding=\"SAME\")(x_in)\n",
    "    x2 = Conv2D(filters=x5_f,kernel_size=(5,5),padding=\"SAME\")(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv2D(filters=x3r_f,kernel_size=(1,1),padding=\"SAME\")(x_in)\n",
    "    x3 = Conv2D(filters=x3_f,kernel_size=(3,3),padding=\"SAME\")(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x4 = Conv2D(filters=x1_f,kernel_size=(1,1),padding=\"SAME\")(x_in)\n",
    "    x4 = Activation('relu')(x4)\n",
    "\n",
    "    out = Concatenate()([x1,x2,x3,x4])\n",
    "    return out\n",
    "\n",
    "\n",
    "def create_model(model, item_code, img_shape, grayscale=False, batch_size=32, test_or_val='test', epochs=10, model_save=True):\n",
    "    \n",
    "    # flow_from_directory를 통해 이미지 불러오기\n",
    "    train_gen = ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "    test_gen = ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "    val_gen = ImageDataGenerator(preprocessing_function=image_preprocessing)\n",
    "\n",
    "    if grayscale:\n",
    "        color_mode = 'grayscale'\n",
    "    else:\n",
    "        color_mode = 'rgb'\n",
    "\n",
    "    train_flow_gen = train_gen.flow_from_directory(\n",
    "        directory=f'./model_images/{item_code}/train', color_mode = color_mode,\n",
    "        target_size=img_shape[:2], class_mode='categorical', batch_size=batch_size, shuffle=False)\n",
    "    test_flow_gen = test_gen.flow_from_directory(\n",
    "        directory=f'./model_images/{item_code}/test', color_mode = color_mode,\n",
    "        target_size=img_shape[:2], class_mode='categorical', batch_size=batch_size, shuffle=False)\n",
    "    if test_or_val == 'val':\n",
    "        val_flow_gen = val_gen.flow_from_directory(\n",
    "            directory=f'./model_images/{item_code}/validation', color_mode = color_mode,\n",
    "            target_size=img_shape[:2], class_mode='categorical', batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    print(f'>> directory read : {train_flow_gen.directory}')\n",
    "    print(f'>>{train_flow_gen.class_indices}')\n",
    "    print(f'>> image_shape: {train_flow_gen.image_shape}')\n",
    "    print(f'>> train_count: {train_flow_gen.n}')\n",
    "    print(f'>> test_count: {test_flow_gen.n}')\n",
    "\n",
    "\n",
    "    # 학습 모델\n",
    "\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------------------------------\n",
    "    # PDPROG    # PDPROG    # PDPROG    # PDPROG    # PDPROG    # PDPROG    # PDPROG    # PDPROG    # PDPROG    # PDPROG    # PDPROG\n",
    "    if model == 'pdprog':\n",
    "        model_name = 'PdProg'\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (2,2), activation='relu', input_shape=img_shape),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(64, (2,2), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(128, (2,2), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(256,activation='relu'),\n",
    "            tf.keras.layers.Dense(train_flow_gen.num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.summary()\n",
    "        model.compile(loss = 'categorical_crossentropy',\n",
    "                      optimizer = 'adam',\n",
    "                      metrics = ['accuracy'])\n",
    "    ##------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------------------------\n",
    "    # GoogleNet    # GoogleNet    # GoogleNet    # GoogleNet    # GoogleNet    # GoogleNet    # GoogleNet    # GoogleNet    # GoogleNet\n",
    "    elif model == 'googlenet':\n",
    "        model_name = 'GoogleNet'\n",
    "        input_data = Input(shape=(400,400,3))\n",
    "        x = Conv2D(filters=64,kernel_size=(7,7),strides=(2,2),padding=\"SAME\")(input_data)\n",
    "        x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding=\"SAME\")(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "\n",
    "        x = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding=\"SAME\")(x)\n",
    "        x = Conv2D(filters=192,kernel_size=(3,3),strides=(1,1),padding=\"SAME\")(x)\n",
    "\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding=\"SAME\")(x)\n",
    "\n",
    "\n",
    "        x = inception(x,64,96,128,16,32,32)\n",
    "        x = inception(x,128,128,192,32,96,64)\n",
    "\n",
    "        x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding=\"SAME\")(x)\n",
    "        x = inception(x,192,96,208,16,48,64)\n",
    "\n",
    "        ax1 = AveragePooling2D(pool_size=(5,5),strides=(3,3))(x)\n",
    "        ax1 = Conv2D(filters=128,kernel_size=(1,1),padding=\"SAME\")(ax1)\n",
    "        ax1 = Flatten()(ax1)\n",
    "        ax1 = Dense(1024,activation=\"relu\")(ax1)\n",
    "        ax1 = Dropout(0.7)(ax1)\n",
    "        ax1 = Dense(6,activation=\"softmax\")(ax1)\n",
    "\n",
    "        x = inception(x,160,112,224,24,64,64)\n",
    "        x = inception(x,128,128,256,24,64,64)\n",
    "\n",
    "        x = inception(x,112,114,288,32,64,64)\n",
    "\n",
    "        ax2 = AveragePooling2D(pool_size=(5,5),strides=(3,3))(x)\n",
    "        ax2 = Conv2D(filters=128,kernel_size=(1,1),padding=\"SAME\")(ax2)\n",
    "        ax2 = Flatten()(ax2)\n",
    "        ax2 = Dense(1024,activation=\"relu\")(ax2)\n",
    "        ax2 = Dropout(0.7)(ax2)\n",
    "        ax2 = Dense(6,activation=\"softmax\")(ax2)\n",
    "\n",
    "        x = inception(x,256,160,320,32,128,128)\n",
    "        x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding=\"SAME\")(x)\n",
    "\n",
    "        x = inception(x,256,160,320,32,128,128)\n",
    "        x = inception(x,384,192,384,48,128,128)\n",
    "\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "\n",
    "        outputs = Dense(6,activation=\"softmax\")(x)\n",
    "        model = tf.keras.models.Model(input_data,[outputs,ax1,ax2],name = 'googlenet')\n",
    "    #------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    elif model == 'vgg16':\n",
    "    # #VGG16    #VGG16    #VGG16    #VGG16    #VGG16    #VGG16    #VGG16    #VGG16    #VGG16    #VGG16    #VGG16    #VGG16    #VGG16\n",
    "        model_name = 'VGG16'\n",
    "        model = VGG16(weights= None, input_shape = (400, 400, 3), classes=6)\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    #\n",
    "    #\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    elif model == 'vgg19':\n",
    "    # #VGG19     #VGG19    #VGG19     #VGG19    #VGG19     #VGG19    #VGG19     #VGG19    #VGG19     #VGG19    #VGG19     #VGG19\n",
    "        model_name = 'VGG19'\n",
    "        model = VGG19(weights=None, input_shape = (400, 400, 3), classes=6)\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    #\n",
    "    #\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    # #AlexNet    #AlexNet    #AlexNet    #AlexNet    #AlexNet    #AlexNet    #AlexNet    #AlexNet    #AlexNet    #AlexNet    #AlexNet\n",
    "    elif model == 'alexnet':\n",
    "        model_name = 'AlexNet'\n",
    "        input_shape = (400, 400, 3)\n",
    "        x = Input(shape = input_shape, name='INPUT')\n",
    "\n",
    "        # CONV\n",
    "        conv1 = Conv2D(filters=96, kernel_size=11, activation='relu', strides=4, name='CONV_1')(x)\n",
    "        pool1 = MaxPooling2D((3,3), strides=2, name='POOL_1')(conv1)  # overlapped pooling\n",
    "        # lrn1 = local_response_normalization(conv1,depth_radius=5, bias=2, alpha=0.0001, beta=0.75)\n",
    "        lrn1 = BatchNormalization(name='LRN_1')(pool1)\n",
    "\n",
    "        conv2 = Conv2D(filters=256, kernel_size=5, activation='relu', strides=1, padding='same', name='CONV_2')(lrn1)\n",
    "        pool2 = MaxPooling2D((3,3), strides=2, name='POOL_2')(conv2)\n",
    "        # lrn2 = local_response_normalization(conv2,depth_radius=5, bias=2,  alpha=0.0001, beta=0.75)\n",
    "        lrn2 = BatchNormalization(name='LRN_2')(pool2)\n",
    "\n",
    "        conv3 = Conv2D(filters=384, kernel_size=3, activation='relu', strides=1, padding='same', name='CONV_3')(lrn2)\n",
    "        conv4 = Conv2D(filters=384, kernel_size=3, activation='relu', strides=1, padding='same', name='CONV_4')(conv3)\n",
    "        conv5 = Conv2D(filters=256, kernel_size=3, activation='relu', strides=1, padding='same', name='CONV_5')(conv4)\n",
    "        pool3 = MaxPooling2D((3,3), strides=2, name='POOL_3')(conv5)\n",
    "\n",
    "        # FC\n",
    "        f = Flatten()(pool3)\n",
    "        f = Dense(512, activation='relu', name='FC_1')(f)\n",
    "        # f = Dropout(0.5)(f)  # 논문 parameter 0.5 이용\n",
    "        # f = Dense(4096, activation='relu', name='FC_2')(f)\n",
    "        # f = Dropout(0.5)(f)\n",
    "        out = Dense(6, activation='softmax', name='OUTPUT')(f)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs=x, outputs=[out])\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    # #ResNetV2    #ResNetV2    #ResNetV2    #ResNetV2    #ResNetV2    #ResNetV2    #ResNetV2    #ResNetV2    #ResNetV2    #ResNetV2\n",
    "    elif model == 'resnet_v2':\n",
    "        model_name = 'ResNet_v2'\n",
    "        model = ResNet50V2(weights=None, input_shape=(400, 400, 3), classes=6)\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    #\n",
    "    #\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    # #Inception ResNet    #Inception ResNet    #Inception ResNet    #Inception ResNet    #Inception ResNet    #Inception ResNet\n",
    "    elif model == 'inception_resnet':\n",
    "        model_name = 'Inception Resnet'\n",
    "        model = InceptionResNetV2(weights = None, input_shape=(400, 400, 3), classes=6)\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    #\n",
    "    #\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "    #ResNet101    #ResNet101    #ResNet101    #ResNet101    #ResNet101    #ResNet101    #ResNet101    #ResNet101    #ResNet101\n",
    "    elif model == 'resnet101':\n",
    "        model_name = 'ResNet101'\n",
    "        model = ResNet101(weights=None, input_shape=(400, 400, 3), classes=6)\n",
    "    # #------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    print(model_name)\n",
    "    model.summary()\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    # 체크포인트\n",
    "    cb_checkpoint = ModelCheckpoint(filepath=f'model_hdf5/{item_code}_defect.h5', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                    save_weight_only=True)\n",
    "    \n",
    "    if test_or_val == 'test':\n",
    "        validation_data = test_flow_gen\n",
    "    elif test_or_val == 'val':\n",
    "        validation_data = val_flow_gen\n",
    "\n",
    "\n",
    "    if model_save:\n",
    "        history = model.fit(train_flow_gen,\n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs,\n",
    "                            callbacks =[cb_checkpoint],\n",
    "                            validation_data=validation_data,\n",
    "                            steps_per_epoch= int(math.ceil(1. * train_flow_gen.n / batch_size,)),\n",
    "                            validation_steps = int(math.ceil(1. * test_flow_gen.n / batch_size))\n",
    "                            )\n",
    "    else:\n",
    "        history = model.fit(train_flow_gen,\n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=validation_data,\n",
    "                            steps_per_epoch= int(math.ceil(1. * train_flow_gen.n / batch_size,)),\n",
    "                            validation_steps = int(math.ceil(1. * val_flow_gen.n / batch_size))\n",
    "                            )\n",
    "    if test_or_val == 'test':\n",
    "        model.evaluate(validation_data, batch_size = int(math.ceil(1. * test_flow_gen.n / batch_size)))\n",
    "    elif test_or_val == 'val':\n",
    "        model.evaluate(validation_data, batch_size = int(math.ceil(1. * val_flow_gen.n / batch_size)))\n",
    "\n",
    "\n",
    "    # confusion matrix 출력\n",
    "    if test_or_val == 'test':\n",
    "        real_target = test_flow_gen.labels\n",
    "        predict_target = []\n",
    "        for i in model.predict(test_flow_gen):\n",
    "            predict_target.append(np.argmax(i))\n",
    "            \n",
    "    if test_or_val == 'val':\n",
    "        real_target = val_flow_gen.labels\n",
    "        predict_target = []\n",
    "        for i in model.predict(val_flow_gen):\n",
    "            predict_target.append(np.argmax(i))\n",
    "            \n",
    "    predict_target = np.asarray(predict_target)\n",
    "    con = tf.math.confusion_matrix(labels=real_target, predictions=predict_target)\n",
    "    print('\\n\\n\\n\\n>> confusion_matrix')\n",
    "    print(list(train_flow_gen.class_indices.keys()))\n",
    "    print(con)\n",
    "\n",
    "    # 학습 그래프 출력\n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accucarcy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42a7d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model = [pdprog, googlenet, vgg16, vgg19, alexnet, resnet_v2, inception_resnet]\n",
    "\n",
    "model = create_model(\n",
    "    model = 'alexnet',\n",
    "    item_code='DA4649_rotate', # 품목코드. ./model_images 쪽에서 동일한 폴더명을 읽어오고, 추후 저장시 해당 품목코드를 기반으로 저장\n",
    "    img_shape=(400, 400, 3),\n",
    "    grayscale = False, # False일 경우 rgb, True일 경우 grayscale\n",
    "    batch_size=32, # 모델 훈련 batch_size\n",
    "    test_or_val='test', # 검증세트를 'test' or 'val'로 설정\n",
    "    epochs=10,\n",
    "    model_save=True # True일 경우 학습모델(.h5) 저장\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}